{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# data processing packages\n",
    "import numpy as np   \n",
    "import pandas as pd \n",
    "\n",
    "from scipy import stats # look at scipy\n",
    "from scipy import linalg\n",
    "from scipy import *\n",
    "\n",
    "import random\n",
    "\n",
    "# machine leanring packages\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "# RMSprop, Adadelta\n",
    "from keras.regularizers import *\n",
    "from keras.initializers import *\n",
    "from keras.activations import *\n",
    "\n",
    "from utils_keras import *\n",
    "from utils_dataPrepro import *\n",
    "\n",
    "# from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.merge import *\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notes:\n",
    "\n",
    "# ---Ini:            \n",
    "#     orthogonal: https://smerity.com/articles/2016/orthogonal_init.html\n",
    "#     identity, Xavier, He's\n",
    "\n",
    "# ---Activation:     \n",
    "#     tan, sigmod by default\n",
    "\n",
    "# ---Regularization: \n",
    "#     dropout on non-recurrent connections \n",
    "#     batch normalization\n",
    "\n",
    "# unstable or not decreasing training loss: lr, representability, e.g., number of neursons, layers, etc..\n",
    "# watch out for the amount difference between regularization and loss  \n",
    "# large minibatch -> large lr\n",
    "# large network -> large lr\n",
    "\n",
    "\n",
    "# learning speed, repren, regular\n",
    "\n",
    "# TO DO:\n",
    "    \n",
    "# more component\n",
    "# muliti-input-muliti-output method\n",
    "# log transformation\n",
    "# integrate trend \n",
    "# attention for peridoic time series\n",
    "\n",
    "# multistep ahead:  multi-output rnn, a.k.a. state space model \n",
    "#                   seq2seq rnn \n",
    "\n",
    "# Stat-space model: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4640, 199, 2) (4640, 1) (1300, 199, 2) (1300, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files_list=[\"../../dataset/dataset_ts/air_xtrain.dat\", \\\n",
    "            \"../../dataset/dataset_ts/air_xtest.dat\",\\\n",
    "            \"../../dataset/dataset_ts/air_ytrain.dat\", \\\n",
    "            \"../../dataset/dataset_ts/air_ytest.dat\"]\n",
    "\n",
    "xtrain, ytrain, xtest, ytest, tr_shape, ts_shape = \\\n",
    "prepare_train_test_data( True, files_list)\n",
    "\n",
    "\n",
    "xtrain = np.reshape( xtrain, (tr_shape[0], tr_shape[1]-1, -1) )\n",
    "ytrain = np.reshape( ytrain, (tr_shape[0], 1) ) \n",
    "xtest  = np.reshape( xtest,  (ts_shape[0], ts_shape[1]-1, -1) )\n",
    "ytest = np.reshape(  ytest,  (ts_shape[0], 1) )\n",
    "\n",
    "print np.shape(xtrain), np.shape(ytrain), np.shape(xtest), np.shape(ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_raw_diff(x):\n",
    "    cnt = len( list(x) )\n",
    "    steps = len(x[0])\n",
    "    \n",
    "    raw  = []\n",
    "    diff = []\n",
    "    last = []\n",
    "    \n",
    "    for i in xrange(cnt):\n",
    "        raw.append( [j[0] for j in x[i]] )\n",
    "        last.append( x[i][steps-1][0] )\n",
    "        diff.append( [j[1] for j in x[i]] )\n",
    "\n",
    "    return np.asarray(raw), np.asarray(diff), np.asarray(last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4640, 199, 1) (4640, 199, 1) (4640, 1)\n",
      "(1300, 199, 1) (1300, 199, 1) (1300, 1)\n"
     ]
    }
   ],
   "source": [
    "raw_tr, diff_tr, last_tr = split_raw_diff(xtrain)\n",
    "raw_ts, diff_ts, last_ts = split_raw_diff(xtest)\n",
    "\n",
    "raw_tr  = np.reshape( raw_tr,  (tr_shape[0], tr_shape[1]-1, -1) )\n",
    "diff_tr = np.reshape( diff_tr, (tr_shape[0], tr_shape[1]-1, -1) )\n",
    "last_tr = np.reshape( last_tr, (tr_shape[0],  -1) )\n",
    "\n",
    "raw_ts  = np.reshape( raw_ts,  (ts_shape[0], ts_shape[1]-1, -1) )\n",
    "diff_ts = np.reshape( diff_ts, (ts_shape[0], ts_shape[1]-1, -1) )\n",
    "last_ts = np.reshape( last_ts, (ts_shape[0],  -1) )\n",
    "\n",
    "ytrain = np.reshape( ytrain, (tr_shape[0], 1) ) \n",
    "ytest = np.reshape(  ytest,  (ts_shape[0], 1) )\n",
    "\n",
    "print np.shape(raw_tr), np.shape(diff_tr), np.shape(last_tr)\n",
    "print np.shape(raw_ts), np.shape(diff_ts), np.shape(last_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plain discriminative \n",
    "\n",
    "# network set-up\n",
    "in_out_neurons = 1\n",
    "hidden_neurons = 256\n",
    "win_size = 200\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "disc_xtrain = np.reshape( xtrain, [-1, win_size, in_out_neurons] )\n",
    "disc_xtest  = np.reshape( xtest,  [-1, win_size, in_out_neurons] )\n",
    "\n",
    "disc_ytrain = ytrain\n",
    "disc_ytest  = ytest\n",
    "\n",
    "print np.shape(disc_xtrain),np.shape(disc_ytrain),np.shape(disc_xtest),\\\n",
    "np.shape(disc_ytest)\n",
    "\n",
    "# optimizer\n",
    "sgd  = SGD(lr = 0.01, momentum = 0.9, nesterov = True)\n",
    "rms  = RMSprop(lr = 0.05,  rho = 0.9, epsilon  = 1e-08, decay = 0.0)\n",
    "\n",
    "adam = Adam(lr = 0.005, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, decay = 0.0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add( LSTM(hidden_neurons, input_dim = in_out_neurons, return_sequences = False, \\\n",
    "                input_shape = [batch_size, win_size, in_out_neurons ], \\\n",
    "#               input_length = win_size, \\\n",
    "#               activation ='tanh',\\\n",
    "#               dropout = 0.1,\\\n",
    "#               kernel_regularizer = l2(0.2), \n",
    "#               recurrent_regularizer = l2(0.1),\\\n",
    "#               !change!\n",
    "                kernel_initializer    = glorot_normal(), \\\n",
    "                recurrent_initializer = glorot_normal() ))\n",
    "# change: activiation\n",
    "\n",
    "# model.add( LSTM(hidden_neurons, return_sequences = False, \\\n",
    "# #               input_shape = [batch_size, win_size, in_out_neurons ], \\\n",
    "# #               input_length = win_size, \\\n",
    "#               activation ='tanh',\\\n",
    "# #               dropout = 0.1,\\\n",
    "# #               kernel_regularizer = l2(0.2), \n",
    "# #               recurrent_regularizer = l2(0.1),\\\n",
    "# #               !change!\n",
    "#                 kernel_initializer    = glorot_normal(), \\\n",
    "#                 recurrent_initializer = glorot_normal() ))\n",
    "\n",
    "\n",
    "# identity ini\n",
    "# he's ini:   he_normal()\n",
    "# xavier ini: glorot_normal()\n",
    "# orthogonal: Orthogonal()\n",
    "\n",
    "\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(128,\\\n",
    "#                   kernel_regularizer = l2(0.01), \\\n",
    "                    kernel_initializer = he_normal()))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(64, \\\n",
    "#                   kernel_regularizer = l2(0.01), \\\n",
    "                    kernel_initializer = he_normal()))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(32, \\\n",
    "#                   kernel_regularizer = l2(0.01), \\\n",
    "                    kernel_initializer = he_normal()))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1,  \\\n",
    "#                   kernel_regularizer = l2(0.01), \\\n",
    "                    kernel_initializer = he_normal()))\n",
    "model.add(Activation(\"linear\"))\n",
    "\n",
    "\n",
    "# training\n",
    "model.compile(loss = \"mean_squared_error\", optimizer = adam)\n",
    "\n",
    "\n",
    "model.fit( disc_xtrain, disc_ytrain, shuffle = True, \\\n",
    "           callbacks = [ \\\n",
    "           TestCallback( (disc_xtest, disc_ytest), (disc_xtrain, disc_ytrain) ) ], \\\n",
    "           batch_size = batch_size, epochs = 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generative model\n",
    "\n",
    "# set-up\n",
    "in_out_neurons = 1\n",
    "hidden_neurons = 256\n",
    "win_size = 200    \n",
    "    \n",
    "# prepare data\n",
    "ytrain = expand_y( xtrain_df.as_matrix(), ytrain_df.as_matrix() )\n",
    "ytest  = expand_y( xtest_df.as_matrix(),  ytest_df.as_matrix()  )\n",
    "\n",
    "gen_xtrain = np.reshape( xtrain, [-1, win_size, 1] )\n",
    "gen_ytrain = np.reshape( ytrain, [-1, win_size, 1] )\n",
    "\n",
    "gen_xtest  = np.reshape( xtest, [-1, win_size, 1] )\n",
    "gen_ytest  = np.reshape( ytest, [-1, win_size, 1] )\n",
    "\n",
    "print np.shape(gen_xtrain), np.shape(gen_ytrain), np.shape(gen_xtest), np.shape(gen_ytest)\n",
    "\n",
    "\n",
    "# optimizer \n",
    "adam  = Adam(lr = 0.002, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, decay = 0.0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add( LSTM(hidden_neurons, input_dim = in_out_neurons, return_sequences = True, \\\n",
    "                input_length = win_size,\\\n",
    "                activation   = 'tanh',\\\n",
    "#                dropout = 0.1,\\\n",
    "#                kernel_regularizer = l2(0.15), \\\n",
    "#                recurrent_regularizer = l2(0.15), \\\n",
    "                kernel_initializer    = glorot_normal(), \\\n",
    "                recurrent_initializer = glorot_normal() ) )\n",
    "\n",
    "\n",
    "# identity ini\n",
    "# he's ini:   he_normal()\n",
    "# xavier ini: glorot_normal()\n",
    "# orthogonal: Orthogonal() \n",
    "\n",
    "\n",
    "# model.add(Dropout(0.1))\n",
    "model.add(TimeDistributed(Dense(128, activation = 'relu',\\\n",
    "#                                     kernel_regularizer = l2(0.1), \\\n",
    "                                    kernel_initializer = he_normal() ) ))\n",
    "\n",
    "model.add(TimeDistributed(Dense(64, activation = 'relu',\\\n",
    "#                                     kernel_regularizer = l2(0.01), \\\n",
    "                                    kernel_initializer = he_normal() ) ))\n",
    "\n",
    "model.add(TimeDistributed(Dense(1,  activation = 'linear',\\\n",
    "#                                     kernel_regularizer = l2(0.01), \\\n",
    "                                    kernel_initializer = he_normal() ) ))\n",
    "\n",
    "\n",
    "# training\n",
    "model.compile( loss = \"mean_squared_error\", optimizer = adam )\n",
    "\n",
    "\n",
    "model.fit( gen_xtrain, gen_ytrain, shuffle=True,  \\\n",
    "           callbacks = [ TestCallback_Generative( \\\n",
    "                         (gen_xtest, gen_ytest), (gen_xtrain, gen_ytrain) ) ], \\\n",
    "                         batch_size = 128, epochs = 500 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# State space model \n",
    "# with non-overlapping local data\n",
    "\n",
    "#  network set-up\n",
    "local_size = 5\n",
    "in_out_neurons = local_size\n",
    "hidden_neurons = 512\n",
    "win_size = 200/5\n",
    "\n",
    "# # validation on each epoch \n",
    "# class TestCallback_insight(Callback):\n",
    "#     def __init__(self, test_data):\n",
    "#         self.test_data = test_data\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         x, y = self.test_data\n",
    "#         loss, mse = self.model.evaluate(x, y, verbose=0)\n",
    "        \n",
    "#         py = self.model.predict(x, verbose=0)\n",
    "#         cnt = len(y)\n",
    "#         err = [ (y[i][0]-py[i][0])**2 for i in range(cnt)]\n",
    "        \n",
    "#         print('\\nTesting loss: {}, acc: {}, mean: {} \\n'.format(\\\n",
    "#                loss, sqrt(mse), mean(err) ))\n",
    "\n",
    "def expand_x_local_non_overlapping( local_size, list_data):\n",
    "    \n",
    "    cnt = len(list_data)\n",
    "    steps = len(list_data[0])\n",
    "    tmp_dta = []\n",
    "    \n",
    "    for i in range(cnt):\n",
    "        tmp_dta.append([])\n",
    "        for j in range( local_size-1, steps, local_size ):\n",
    "            tmp_dta[-1].append( list_data[i][ j-local_size+1:j+1 ] )\n",
    "    \n",
    "    return tmp_dta\n",
    "\n",
    "\n",
    "disc_xtrain = np.array( expand_x_local_non_overlapping( local_size, list(xtrain) ) )\n",
    "disc_xtest  = np.array( expand_x_local_non_overlapping( local_size, list(xtest) ) )\n",
    "\n",
    "disc_ytrain = ytrain\n",
    "disc_ytest  = ytest\n",
    "\n",
    "print np.shape(disc_xtrain), np.shape(disc_ytrain), np.shape(disc_xtest), \\\n",
    "np.shape(disc_ytest)\n",
    "\n",
    "# optimizer \n",
    "adam = Adam(lr = 0.007, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, decay = 0.0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(hidden_neurons, input_dim = in_out_neurons, return_sequences = False, \\\n",
    "               input_length = win_size, \\\n",
    "               activation = 'tanh', \\\n",
    "#                dropout = 0.1,\\\n",
    "#                kernel_regularizer = l2(0.1),      recurrent_regularizer = l2(0.1), \\\n",
    "               kernel_initializer    = glorot_normal(), \\\n",
    "               recurrent_initializer = glorot_normal() ))\n",
    "# identity ini\n",
    "# he's ini:   he_normal()\n",
    "# xavier ini: glorot_normal()\n",
    "# orthogonal: Orthogonal() \n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# kernel_regularizer = l2(0.1), \\\n",
    "model.add(Dense(128,\\\n",
    "                    kernel_initializer = he_normal()))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(64, \\\n",
    "                    kernel_initializer = he_normal()))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(32, \\\n",
    "                    kernel_initializer = he_normal()))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1,\\\n",
    "                    kernel_initializer = he_normal()))\n",
    "model.add(Activation(\"linear\"))\n",
    "\n",
    "\n",
    "# training \n",
    "model.compile(loss=\"mean_squared_error\", optimizer = adam)\n",
    "\n",
    "\n",
    "model.fit( disc_xtrain, disc_ytrain, shuffle=True, \\\n",
    "           callbacks = [ TestCallback( (disc_xtest, disc_ytest), (disc_xtrain, disc_ytrain) ) ], \\\n",
    "           batch_size = 256, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# validation on each epoch \n",
    "class TestCallback_ada(Callback):\n",
    "    def __init__(self, test_data, train_data):\n",
    "        \n",
    "        self.test_data  = test_data        \n",
    "        self.train_data = train_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        raw_ts, diff_ts, last_ts, y_ts = self.test_data\n",
    "        raw_tr, diff_tr, last_tr, y_tr = self.train_data\n",
    "        \n",
    "        py_tr = self.model.predict( [raw_tr, diff_tr, last_tr], verbose=0)\n",
    "        py_ts = self.model.predict( [raw_ts, diff_ts, last_ts], verbose=0)\n",
    "        \n",
    "        size_tr = len(y_tr)\n",
    "        size_ts = len(y_ts)\n",
    "        \n",
    "        err_tr = [ (y_tr[i][0] - py_tr[i][0])**2 for i in range(size_tr) ]\n",
    "        err_ts = [ (y_ts[i][0] - py_ts[i][0])**2 for i in range(size_ts) ]\n",
    "        \n",
    "        loss = self.model.evaluate([raw_ts, diff_ts, last_ts], y_ts, verbose=0)\n",
    "        \n",
    "        with open(\"res/tsRnn_ada.txt\", \"a\") as text_file:\n",
    "            text_file.write(\"At epoch %d: loss %f, train %f, test %f\\n\" % ( epoch, loss, sqrt(mean(err_tr)),\\\n",
    "                                                                           sqrt(mean(err_ts))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/layers/core.py:635: UserWarning: `output_shape` argument not specified for layer lambda_1 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `[(None, 1), (None, 1)]` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:42: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/keras/legacy/layers.py:460: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/usr/local/lib/python2.7/dist-packages/keras/layers/core.py:635: UserWarning: `output_shape` argument not specified for layer lambda_2 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:45: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "WARNING (theano.tensor.blas): We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
      "WARNING:theano.tensor.blas:We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4352/4640 [===========================>..] - ETA: 13s - loss: 768667.0221"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d3de3c190d1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m                               \u001b[0mperiod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMODEL_CHECK_PERIOD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mraw_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiff_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_tr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m          \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m           \u001b[1;33m[\u001b[0m\u001b[0mTestCallback_ada\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mraw_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiff_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m                              \u001b[1;33m[\u001b[0m \u001b[0mraw_ts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiff_ts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_ts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1502\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1504\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1506\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1154\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1157\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    987\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0;32m    988\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 989\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    990\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mp\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    976\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m                                                 self, node)\n\u001b[0m\u001b[0;32m    979\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/guo/.theano/compiledir_Linux-4.4--generic-x86_64-with-Ubuntu-14.04-trusty-x86_64-2.7.6-64/scan_perform/mod.cpp:6946)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mvalue_zeros\u001b[1;34m(self, shape)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mvalue_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m         \"\"\"\n\u001b[0;32m    553\u001b[0m         \u001b[0mCreate\u001b[0m \u001b[0man\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mof\u001b[0m \u001b[1;36m0\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#--- PARAMETERS ---\n",
    "N_DIM = 1\n",
    "N_RNN = 64\n",
    "\n",
    "LR = 0.005\n",
    "\n",
    "WIN_SIZE = 200\n",
    "\n",
    "MODEL_CHECK_PERIOD = 2\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# --- Prepare ----\n",
    "\n",
    "input_raw  = Input(shape = ( WIN_SIZE -1, 1 ), dtype='float32', name='input_raw')\n",
    "input_diff = Input(shape = ( WIN_SIZE -1, 1 ), dtype='float32', name='input_diff')\n",
    "# smoothing last values\n",
    "input_last = Input(shape = ( 1, ), dtype='float32', name='input_last')\n",
    "\n",
    "with open(\"res/tsRnn_ada.txt\", \"w\") as text_file:\n",
    "    text_file.close()\n",
    "        \n",
    "# --- build the network ---    \n",
    "\n",
    "def difference(pair_of_tensors):\n",
    "    x, y = pair_of_tensors\n",
    "    return x - y\n",
    "\n",
    "def one_minus(tensor):\n",
    "    \n",
    "    return K.ones(1) - tensor\n",
    "    \n",
    "#     return [1.0-i for i in tensor]\n",
    "\n",
    "hidden_raw  = LSTM(N_RNN)( input_raw )\n",
    "output_raw  = Dense(1, activation='relu')(hidden_raw)\n",
    "\n",
    "hidden_diff = LSTM(N_RNN)( input_diff )\n",
    "output_diff = Dense(1, activation='relu')(hidden_diff)\n",
    "output_diff = Add()( [output_diff, input_last] )\n",
    "\n",
    "weight_var = Lambda(difference)([output_diff, output_raw])\n",
    "\n",
    "diff_prob = Dense(1, activation='sigmoid')( weight_var )\n",
    "weighted_diff = merge([output_diff, diff_prob], name='weighted_diff', mode='mul')\n",
    "\n",
    "raw_prob = Lambda(one_minus)([diff_prob])\n",
    "weighted_raw  = merge([output_raw, raw_prob], name='attention_raw', mode='mul')\n",
    "\n",
    "output_main = Add()( [weighted_diff, weighted_raw] )\n",
    "\n",
    "\n",
    "# --- training ---\n",
    "\n",
    "model = Model(inputs=[ input_raw, input_diff, input_last], outputs=[ output_main ])\n",
    "\n",
    "adam = Adam(lr = LR , beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, decay = 0.0)\n",
    "\n",
    "model.compile(optimizer = adam, loss='mean_squared_error')\n",
    "\n",
    "filepath=\"res/model/weights-{epoch:02d}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath, verbose=0, save_best_only=False, save_weights_only=False,\\\n",
    "                               period=MODEL_CHECK_PERIOD)\n",
    "\n",
    "model.fit([raw_tr, diff_tr, last_tr], [ytrain], epochs = 500, batch_size = BATCH_SIZE,\\\n",
    "          callbacks = \\\n",
    "          [TestCallback_ada( [ raw_tr, diff_tr, last_tr, ytrain ], \\\n",
    "                             [ raw_ts, diff_ts, last_ts, ytest ] ), checkpointer ])\n",
    "                  \n",
    "\n",
    "# # load weights\n",
    "# model.load_weights(\"weights.best.hdf5\")\n",
    "# # Compile model (required to make predictions)\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
